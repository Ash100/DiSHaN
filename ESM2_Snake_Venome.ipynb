{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNwq3rKOHZblrZbwORgj8gD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/DiSHaN/blob/main/ESM2_Snake_Venome.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**How to Use Evolutionary Scale Model 2 (ESM-2) for Predicting Protein Function?**\n",
        "\n",
        "This notebook is developed by **Dr. Ashfaq Ahmad**, and can be used for Research Purposes.\n",
        "\n",
        "For the tutorial section, I am using peptide sequences in two categories, **Target** and **Control**. Control are those known for some therapeutic value.\n",
        "\n",
        "We will use ESM-2 embeddings and to know that is there any sequence from the target pool that are potential hits for future research."
      ],
      "metadata": {
        "id": "hEDDpk4EXlf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ESM-2 (Evolutionary Scale Modeling)** is a state-of-the-art Large Language Model (LLM) specifically designed for protein sequences, developed by **Meta AI**. It is trained on approximately **250 million protein sequences** from the UniRef database, allowing it to learn the complex \"grammar\" of evolution directly from amino acid strings.\n",
        "\n",
        "Unlike traditional models that require 3D structures, ESM-2 uses its **650 million parameters** (in the variant used here) to predict a protein's structure and function solely from its sequence. By transforming amino acids into 1280-dimensional vectors, it captures deep biological insights that are invisible to standard sequence alignment tools."
      ],
      "metadata": {
        "id": "hRfg1HyHYk0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCiuqOgf2wqC",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip install torch transformers sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation 2\n",
        "!pip install git+https://github.com/facebookresearch/esm.git\n",
        "!pip install biopython scikit-learn matplotlib seaborn"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e6Mzjkdy4JlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import librariesimport torch\n",
        "import esm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from Bio import SeqIO\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "print(\"Libraries installed and imported.\")\n",
        ""
      ],
      "metadata": {
        "id": "D21GM7R53KcZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read .fasta file and mention your control sequences\n",
        "FASTA_FILE = \"/content/PEPS.fas\"  # Ensure your file is uploaded to the Colab 'Files' tab\n",
        "CONTROLS = [\n",
        "    \"Zinc metalloproteinase/disintegrin-1\", \"Zinc metalloproteinase/disintegrin-2\", \"Zinc metalloproteinase/disintegrin-3, \"\"Disintegrin obtustatin\",\n",
        "    \"L-aminoacid oxidase\", \"Basic phospholipase A2 F17\",\n",
        "    \"Zinc metalloproteinase-disintegrin-like VAP2A\", \"Thrombin-like enzyme collinein-1\",\n",
        "    \"Kunitz-type serine protease inhibitor PIVL\", \"Cytotoxin 3\",\n",
        "    \"Acidic phospholipase A2 2\", \"L-aminoacid oxidase\", \"Zinc metalloproteinase-disintegrin BlatH1\",\n",
        "    \"Alpha-fibrinogenase\", \"Snake venom 5'-nucleotidase\"\n",
        "]\n",
        "\n",
        "def load_and_clean_fasta(path):\n",
        "    sequences = []\n",
        "    # Regex to keep only valid uppercase Amino Acid letters\n",
        "    aa_regex = re.compile(r'[^ACDEFGHIKLMNPQRSTVWY]')\n",
        "\n",
        "    for record in SeqIO.parse(path, \"fasta\"):\n",
        "        # Ensure uppercase and strip non-sequence text\n",
        "        clean_seq = aa_regex.sub('', str(record.seq).upper())\n",
        "\n",
        "        if clean_seq:\n",
        "            is_control = any(ctrl.lower() in record.description.lower() for ctrl in CONTROLS)\n",
        "            sequences.append({\n",
        "                \"id\": record.description[:50],\n",
        "                \"sequence\": clean_seq,\n",
        "                \"type\": \"Control\" if is_control else \"Target\"\n",
        "            })\n",
        "    return sequences\n",
        "\n",
        "processed_data = load_and_clean_fasta(FASTA_FILE)\n",
        "print(f\"Loaded {len(processed_data)} valid sequences.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IBZXROOu5F0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load ESM-2 Model (650M parameters)\n",
        "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "model.eval()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    print(\"GPU found! Processing with acceleration.\")\n",
        "\n",
        "embeddings_list = []\n",
        "for item in processed_data:\n",
        "    labels, strs, tokens = batch_converter([(item[\"id\"], item[\"sequence\"])])\n",
        "    if torch.cuda.is_available():\n",
        "        tokens = tokens.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results = model(tokens, repr_layers=[33])\n",
        "        reps = results[\"representations\"][33]\n",
        "\n",
        "        # Mean pooling: Average across the length of the sequence\n",
        "        seq_len = len(item[\"sequence\"])\n",
        "        mean_emb = reps[0, 1 : seq_len + 1].mean(0).cpu().numpy()\n",
        "        embeddings_list.append(mean_emb)\n",
        "\n",
        "vectors = np.array(embeddings_list)\n",
        "print(f\"Embeddings generated. Matrix shape: {vectors.shape}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H84lhfMl6M_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Standardize and run PCA\n",
        "scaler = StandardScaler()\n",
        "scaled_vectors = scaler.fit_transform(vectors)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "coords = pca.fit_transform(scaled_vectors)\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "df_plot = pd.DataFrame(coords, columns=['PC1', 'PC2'])\n",
        "df_plot['Type'] = [item['type'] for item in processed_data]\n",
        "df_plot['ID'] = [item['id'] for item in processed_data]\n",
        "\n",
        "print(f\"PCA complete. Variance explained: {sum(pca.explained_variance_ratio_)*100:.1f}%\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tZZnTptM6Xkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install adjustText\n",
        "!pip install adjustText"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mkCy2px-7LKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Save results to a CSV\n",
        "df_plot.to_csv(\"esm2_clustering_results.csv\", index=False)\n",
        "print(\"Results saved to 'esm2_clustering_results.csv'. Check the folder icon on the left.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DRiKqISt6pVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. K-Means Clustering (Explicit Grouping)\n",
        "We will use K-Means. It mathematically assigns every one of your 110 sequences to a specific cluster. We will then check if our \"Targets\" are being put into the same cluster as your \"Controls.\""
      ],
      "metadata": {
        "id": "FNlfaJUiCn1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot PCA results and Elbow Plot\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 1. VALIDATION: THE ELBOW METHOD ---\n",
        "inertia = []\n",
        "K = range(1, 16)\n",
        "for k in K:\n",
        "    kmeanModel = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "    kmeanModel.fit(scaled_vectors)\n",
        "    inertia.append(kmeanModel.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K, inertia, 'bx-', markersize=8, linewidth=2, color='#4682B4')\n",
        "plt.xlabel('Number of Clusters (k)', weight='bold')\n",
        "plt.ylabel('Inertia (Error)', weight='bold')\n",
        "plt.title('The Elbow Method: Validating Optimal Cluster Count', fontsize=15, pad=15)\n",
        "sns.despine()\n",
        "plt.grid(False)\n",
        "\n",
        "# SAVE ELBOW PLOT (600 DPI)\n",
        "plt.savefig(\"Venom_Elbow_Plot_Validation_600DPI.png\", dpi=600, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# --- 2. APPLY K-MEANS CLUSTERING ---\n",
        "# Set to 10 based on your Elbow analysis\n",
        "n_clusters = 10\n",
        "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
        "df_plot['Cluster'] = kmeans.fit_predict(scaled_vectors)\n",
        "\n",
        "# --- 3. VISUALIZE CLUSTERS WITH CATEGORICAL LABELS ---\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.set_style(\"ticks\")\n",
        "\n",
        "# Plot using Cluster IDs as colors\n",
        "scatter = sns.scatterplot(\n",
        "    data=df_plot, x='PC1', y='PC2',\n",
        "    hue='Cluster', palette='tab10', # tab10 is great for 10 distinct groups\n",
        "    style='Type', s=120, alpha=0.8, edgecolor='w', zorder=1\n",
        ")\n",
        "\n",
        "# Overlay our \"Keyword Centroid\" labeling logic to see where categories sit\n",
        "texts = []\n",
        "for ctrl_keyword in CONTROLS:\n",
        "    mask = df_plot['ID'].str.contains(ctrl_keyword, case=False, na=False)\n",
        "    subset = df_plot[mask]\n",
        "    if not subset.empty:\n",
        "        center_x, center_y = subset['PC1'].mean(), subset['PC2'].mean()\n",
        "        texts.append(plt.text(center_x, center_y, ctrl_keyword,\n",
        "                             fontsize=9, weight='bold', color='black',\n",
        "                             bbox=dict(facecolor='white', alpha=0.6, edgecolor='none')))\n",
        "\n",
        "from adjustText import adjust_text\n",
        "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='black', lw=0.5))\n",
        "\n",
        "plt.title(f\"K-Means Clustering of Venom Sequences (k={n_clusters})\", fontsize=16)\n",
        "plt.xlabel(f\"PC1\", weight='bold')\n",
        "plt.ylabel(f\"PC2\", weight='bold')\n",
        "sns.despine(trim=True, offset=10)\n",
        "plt.grid(False)\n",
        "\n",
        "# SAVE CLUSTER PLOT (600 DPI)\n",
        "plt.savefig(\"Venom_KMeans_Clusters_600DPI.png\", dpi=600, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# --- 4. EXPORT FINAL RESULTS ---\n",
        "# This creates the table showing which targets share a cluster with controls\n",
        "cluster_summary = df_plot.groupby(['Cluster', 'Type']).size().unstack(fill_value=0)\n",
        "print(\"\\n--- Cluster Composition Table ---\")\n",
        "print(cluster_summary)\n",
        "\n",
        "# Save the full mapping to CSV\n",
        "df_plot.to_csv(\"Final_Sequence_Cluster_Mapping.csv\", index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vB7duBNkCwNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elbow Plot**<br> Elbow Plot, a standard diagnostic tool used to determine the optimal number of clusters ($k$) for a dataset—in our case, the 113 protein sequences.It provides a mathematical \"reality check\" for your PCA plot. While the PCA shows you a map, this plot tells you how many \"neighborhoods\" actually exist on that map.\n",
        "**Key Components of the Graph:X-Axis (Number of Clusters $k$):**<br> This represents the number of groups you are asking the computer to create.<br>**Y-Axis (Inertia/Error):**<br> Technically called Within-Cluster Sum of Squares (WCSS). It measures how far away the protein sequences are from the center of their assigned cluster.<br>**High Inertia:**<br> The groups are loose and messy.<br>**Low Inertia:**<br> The groups are tight and cohesive.<br>**The Blue Line:**<br> As you increase the number of clusters, the error always goes down because the groups get smaller and tighter.<br>**How to Interpret Your Specific Result:**<br>To find the \"optimal\" $k$, you look for the \"Elbow\"—the point where the sharp drop slows down and the line starts to level off.The Sharp Drop (k=1 to k=4): Moving from 1 to 4 clusters significantly reduces error. This suggests your sequences are definitely not one giant random blob; they have distinct structural families.<br>**The Elbow Point (k=4):**<br> There is a noticeable \"bend\" at $k=4$. This suggests that 4 is a very strong candidate for the number of major protein families in your dataset.<br>**The Subtle Bend (k=6 to k=8):**<br> You'll notice another slight softening of the curve around 6 or 8. This often happens with venom proteins because you have broad families (like \"Metalloproteinases\") that contain smaller, distinct sub-types.\n",
        "\n",
        "**We went for the 10 clusters based on the recommendation of Elbow PLot**"
      ],
      "metadata": {
        "id": "I9VzMdjyFEAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to calculate the Nearest Neighbours to the Control in Cluster 1, 2, 3, 5, and 6. Because only these clusters contain the Control representation."
      ],
      "metadata": {
        "id": "oTm9G_YCHhWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate Nearest Neighbours to your Control in Specific Cluster\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# --- 1. SET TARGET CLUSTERS ---\n",
        "target_clusters = [1, 2, 3, 5, 6]\n",
        "\n",
        "# --- 2. CALCULATE DISTANCES ---\n",
        "# We use the 'vectors' array (raw ESM-2 embeddings) for maximum precision\n",
        "results_list = []\n",
        "\n",
        "for cluster_id in target_clusters:\n",
        "    # Filter data for this specific cluster\n",
        "    cluster_df = df_plot[df_plot['Cluster'] == cluster_id]\n",
        "\n",
        "    # Get indices for Controls and Targets within this cluster\n",
        "    ctrl_indices = cluster_df[cluster_df['Type'] == 'Control'].index\n",
        "    target_indices = cluster_df[cluster_df['Type'] == 'Target'].index\n",
        "\n",
        "    if len(ctrl_indices) > 0 and len(target_indices) > 0:\n",
        "        # Calculate distance from every control to every target in this cluster\n",
        "        dist_matrix = cdist(vectors[ctrl_indices], vectors[target_indices], metric='euclidean')\n",
        "\n",
        "        for i, ctrl_idx in enumerate(ctrl_indices):\n",
        "            ctrl_name = df_plot.loc[ctrl_idx, 'ID']\n",
        "\n",
        "            # Find top 5 closest targets\n",
        "            distances = dist_matrix[i]\n",
        "            # Get indices of targets sorted by distance\n",
        "            closest_target_sub_indices = np.argsort(distances)[:5]\n",
        "\n",
        "            for rank, sub_idx in enumerate(closest_target_sub_indices):\n",
        "                actual_target_idx = target_indices[sub_idx]\n",
        "                results_list.append({\n",
        "                    \"Cluster\": cluster_id,\n",
        "                    \"Reference Control\": ctrl_name,\n",
        "                    \"Nearest Neighbor (Target)\": df_plot.loc[actual_target_idx, 'ID'],\n",
        "                    \"Distance Score\": round(distances[sub_idx], 4),\n",
        "                    \"Rank\": rank + 1\n",
        "                })\n",
        "\n",
        "# --- 3. FORMAT AND DISPLAY ---\n",
        "nn_df = pd.DataFrame(results_list)\n",
        "\n",
        "if nn_df.empty:\n",
        "    print(\"No matches found. Check if the specified clusters contain both Controls and Targets.\")\n",
        "else:\n",
        "    # Display the top results\n",
        "    print(\"--- Nearest Neighbors to Controls (Top 5 per Control) ---\")\n",
        "    display(nn_df)\n",
        "\n",
        "    # --- 4. SAVE RESULTS ---\n",
        "    nn_df.to_csv(\"Control_Nearest_Neighbors.csv\", index=False)\n",
        "    print(\"\\nResults saved to 'Control_Nearest_Neighbors.csv'\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OprHMkKbHxKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congratulation** -  You are done"
      ],
      "metadata": {
        "id": "QakJgIVKa0-n"
      }
    }
  ]
}