{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/DiSHaN/blob/main/LTRDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline is generated by **Dr. Ashfaq Ahmad** for research purposes. It uses LTRDetector for genomes to identify and plot the presence of LTR Transposons.\n",
        "\n",
        "[Citation of LTRDector](https://link.springer.com/article/10.1186/s12864-019-5796-9)"
      ],
      "metadata": {
        "id": "iCeOOJyDJ3Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 0: Initial Setup and Installation (~ 3 minutes)**\n",
        "#@markdown This cell installs dependencies, compiles Look4LTRs, and mounts Google Drive.\n",
        "print(\"ðŸš€ Starting pipeline setup...\")\n",
        "\n",
        "# 1. Install system dependencies including C++ build tools\n",
        "!apt-get update && apt-get install -y wget unzip cmake build-essential 2>/dev/null\n",
        "\n",
        "# 2. Install Python bioinformatics packages\n",
        "!pip install biopython pandas matplotlib numpy 2>/dev/null\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0ru4dKcEAmd5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Clone LtrDetector - Verified URL**\n",
        "import os\n",
        "import zipfile\n",
        "import subprocess\n",
        "\n",
        "print(\"ðŸ“¥ Cloning LtrDetector with verified URL...\")\n",
        "\n",
        "# Clean up\n",
        "!rm -rf /content/LtrDetector* 2>/dev/null\n",
        "\n",
        "# CORRECT URL: Uses BioinformaticsToolsmith as the owner and 'master' as the branch.\n",
        "correct_zip_url = \"https://github.com/BioinformaticsToolsmith/LtrDetector/archive/refs/heads/master.zip\"\n",
        "zip_path = '/content/LtrDetector.zip'\n",
        "\n",
        "print(f\"\\nâ¬‡ï¸ Downloading from: {correct_zip_url}\")\n",
        "# Use a more verbose wget to see what happens\n",
        "!wget --show-progress -O {zip_path} {correct_zip_url} 2>&1 | tail -5\n",
        "\n",
        "# Check the download properly\n",
        "if os.path.exists(zip_path):\n",
        "    file_size = os.path.getsize(zip_path)\n",
        "    print(f\"\\nðŸ“Š Downloaded file size: {file_size} bytes\")\n",
        "\n",
        "    if file_size > 1000:  # A valid repository zip should be much larger than 1KB\n",
        "        print(\"\\nðŸ“¦ File looks valid. Extracting...\")\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall('/content/')\n",
        "            print(\"âœ… Extraction successful!\")\n",
        "\n",
        "            # The extracted folder will be 'LtrDetector-master'\n",
        "            if os.path.exists('/content/LtrDetector-master'):\n",
        "                !mv /content/LtrDetector-master /content/LtrDetector\n",
        "                print(\"âœ… Repository ready at /content/LtrDetector\")\n",
        "                print(\"\\nðŸ“ First few files:\")\n",
        "                !ls -la /content/LtrDetector/ | head -10\n",
        "            else:\n",
        "                print(\"\\nâš ï¸  Extracted folder has a different name. Listing /content:\")\n",
        "                !ls -la /content/ | grep -i ltr\n",
        "        except zipfile.BadZipFile:\n",
        "            print(\"âŒ File is not a valid ZIP. It may be an error page.\")\n",
        "            print(\"\\nðŸ” First 500 characters of the downloaded file:\")\n",
        "            !head -c 500 {zip_path} 2>/dev/null | cat\n",
        "    else:\n",
        "        print(\"\\nâŒ Download failed or is empty (likely a 404 page).\")\n",
        "        print(\"The URL might be incorrect, or the repository is private/archived.\")\n",
        "else:\n",
        "    print(\"\\nâŒ Download failed completely.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csDBieqqdyCL",
        "outputId": "e5659d2a-68f5-488f-de93-814401871ffc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¥ Cloning LtrDetector with verified URL...\n",
            "\n",
            "â¬‡ï¸ Downloading from: https://github.com/BioinformaticsToolsmith/LtrDetector/archive/refs/heads/master.zip\n",
            "   100K .......... .......... .......... .......... .......... 84.9M\n",
            "   150K .......... .......... .......... .......... .........  1.81M=0.1s\n",
            "\n",
            "2026-01-12 09:33:32 (1.91 MB/s) - â€˜/content/LtrDetector.zipâ€™ saved [204262]\n",
            "\n",
            "\n",
            "ðŸ“Š Downloaded file size: 204262 bytes\n",
            "\n",
            "ðŸ“¦ File looks valid. Extracting...\n",
            "âœ… Extraction successful!\n",
            "âœ… Repository ready at /content/LtrDetector\n",
            "\n",
            "ðŸ“ First few files:\n",
            "total 36\n",
            "drwxr-xr-x 4 root root 4096 Jan 12 09:33 .\n",
            "drwxr-xr-x 1 root root 4096 Jan 12 09:33 ..\n",
            "drwxr-xr-x 2 root root 4096 Jan 12 09:33 groundTruth\n",
            "-rw-r--r-- 1 root root 1364 Jan 12 09:33 HowToCompile.txt\n",
            "-rw-r--r-- 1 root root 5884 Jan 12 09:33 README.md\n",
            "-rw-r--r-- 1 root root   47 Jan 12 09:33 requirements.txt\n",
            "drwxr-xr-x 9 root root 4096 Jan 12 09:33 src\n",
            "-rw-r--r-- 1 root root 1481 Jan 12 09:33 visualize.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 0: Build LtrDetector (Following Official Instructions)**\n",
        "print(\"ðŸš€ Building LtrDetector using official method...\")\n",
        "\n",
        "# 1. Navigate to the src directory (as per README)\n",
        "import os\n",
        "os.chdir('/content/LtrDetector/src')\n",
        "\n",
        "print(\"ðŸ“ Current directory:\", os.getcwd())\n",
        "!ls -la\n",
        "\n",
        "# 2. Create the bin directory (first step in README)\n",
        "print(\"\\nðŸ“¦ Creating bin directory...\")\n",
        "!make bin 2>&1\n",
        "\n",
        "# 3. Build the actual binary (second step in README)\n",
        "print(\"\\nðŸ”¨ Compiling LtrDetector binary...\")\n",
        "!make tr -j4 2>&1\n",
        "\n",
        "# 4. Check if binary was created\n",
        "print(\"\\nðŸ” Checking for compiled binary...\")\n",
        "if os.path.exists('../bin/LtrDetector'):\n",
        "    print(f\"âœ… SUCCESS! Binary created at: /content/LtrDetector/bin/LtrDetector\")\n",
        "    !ls -la ../bin/LtrDetector\n",
        "    !../bin/LtrDetector -help 2>&1 | head -20\n",
        "else:\n",
        "    print(\"âŒ Binary not found. Checking for errors...\")\n",
        "    # Look for any binary files\n",
        "    !find .. -name \"*Ltr*\" -type f -executable 2>/dev/null\n",
        "    !find .. -name \"*ltr*\" -type f -executable 2>/dev/null\n",
        "\n",
        "print(\"\\nðŸ“ Checking all bin directory contents:\")\n",
        "!ls -la ../bin/ 2>/dev/null || echo \"bin directory not found\"\n",
        "\n",
        "# 5. Return to content directory\n",
        "os.chdir('/content')\n",
        "print(\"\\nâœ… Build process completed.\")"
      ],
      "metadata": {
        "id": "n4b_3RKGF71y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80dfe3b-361e-4818-874b-8089c0f8fda4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Building LtrDetector using official method...\n",
            "ðŸ“ Current directory: /content/LtrDetector/src\n",
            "total 64\n",
            "drwxr-xr-x 9 root root  4096 Jan 12 09:33 .\n",
            "drwxr-xr-x 4 root root  4096 Jan 12 09:33 ..\n",
            "drwxr-xr-x 2 root root  4096 Jan 12 09:33 build\n",
            "drwxr-xr-x 2 root root  4096 Jan 12 09:33 exception\n",
            "drwxr-xr-x 2 root root  4096 Jan 12 09:33 .ipynb_checkpoints\n",
            "-rw-r--r-- 1 root root 27113 Jan 12 09:33 Makefile\n",
            "drwxr-xr-x 2 root root  4096 Jan 12 09:33 nonltr\n",
            "drwxr-xr-x 2 root root  4096 Jan 12 09:33 test\n",
            "drwxr-xr-x 2 root root  4096 Jan 12 09:33 tr\n",
            "drwxr-xr-x 2 root root  4096 Jan 12 09:33 utility\n",
            "\n",
            "ðŸ“¦ Creating bin directory...\n",
            "mkdir ../bin\n",
            "mkdir ../bin/exception\n",
            "mkdir ../bin/utility\n",
            "mkdir ../bin/nonltr\n",
            "mkdir ../bin/tr\n",
            "mkdir ../bin/test\n",
            "\n",
            "ðŸ”¨ Compiling LtrDetector binary...\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c test/TestTr.cpp -o ../bin/TestTr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c exception/InvalidInputException.cpp -o ../bin/exception/InvalidInputException.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c exception/FileDoesNotExistException.cpp -o ../bin/exception/FileDoesNotExistException.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c exception/InvalidStateException.cpp -o ../bin/exception/InvalidStateException.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c exception/InvalidOperationException.cpp -o ../bin/exception/InvalidOperationException.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/Tr.cpp -o ../bin/tr/Tr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/BackwardTr.cpp -o ../bin/tr/BackwardTr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/ForwardTr.cpp -o ../bin/tr/ForwardTr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/Candidate.cpp -o ../bin/tr/Candidate.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/PairContainer.cpp -o ../bin/tr/PairContainer.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/ScorerTr.cpp -o ../bin/tr/ScorerTr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c nonltr/Chromosome.cpp -o ../bin/nonltr/Chromosome.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c nonltr/ChromosomeOneDigit.cpp\t-o ../bin/nonltr/ChromosomeOneDigit.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c nonltr/ChromosomeRandom.cpp -o ../bin/nonltr/ChromosomeRandom.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/TrKVisitor.cpp -o ../bin/tr/TrKVisitor.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/TrCsVisitor.cpp -o ../bin/tr/TrCSVisitor.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/TrSineVisitor.cpp -o ../bin/tr/TrSineVisitor.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/FilterTr.cpp -o ../bin/tr/FilterTr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/LtrTe.cpp -o ../bin/tr/LtrTe.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/DetectorTr.cpp -o ../bin/tr/DetectorTr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/MatchTr.cpp -o ../bin/tr/MatchTr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/Util.cpp -o ../bin/utility/Util.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/Location.cpp -o ../bin/utility/Location.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/EmptyLocation.cpp -o ../bin/utility/EmptyLocation.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/LCS.cpp -o ../bin/utility/LCS.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/LCSLen.cpp -o ../bin/utility/LCSLen.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/LCSubStr.cpp -o ../bin/utility/LCSubStr.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/TSD.cpp -o ../bin/utility/TSD.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/EmptyTSD.cpp -o ../bin/utility/EmptyTSD.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/TailFinder.cpp -o ../bin/utility/TailFinder.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/Tail.cpp -o ../bin/utility/Tail.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/EmptyTail.cpp -o ../bin/utility/EmptyTail.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c tr/TrCollector.cpp -o ../bin/tr/TrCollector.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/GlobAlignE.cpp -o ../bin/utility/GlobAlignE.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c utility/LocAlign.cpp -o ../bin/utility/LocAlign.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -c nonltr/ChromListMaker.cpp -o ../bin/nonltr/ChromListMaker.o\n",
            "g++ -std=c++11 -g -O3 -fopenmp -fmessage-length=0  -o ../bin/LtrDetector ../bin/TestTr.o ../bin/exception/InvalidInputException.o ../bin/exception/FileDoesNotExistException.o ../bin/exception/InvalidStateException.o ../bin/exception/InvalidOperationException.o ../bin/tr/Tr.o ../bin/tr/BackwardTr.o ../bin/tr/ForwardTr.o ../bin/tr/Candidate.o ../bin/tr/PairContainer.o ../bin/tr/ScorerTr.o ../bin/nonltr/Chromosome.o ../bin/nonltr/ChromosomeOneDigit.o ../bin/nonltr/ChromosomeRandom.o ../bin/tr/TrKVisitor.o ../bin/tr/TrCSVisitor.o ../bin/tr/TrSineVisitor.o ../bin/tr/FilterTr.o ../bin/tr/LtrTe.o ../bin/tr/DetectorTr.o ../bin/tr/MatchTr.o ../bin/utility/Util.o ../bin/utility/Location.o ../bin/utility/EmptyLocation.o ../bin/utility/LCS.o ../bin/utility/LCSLen.o ../bin/utility/LCSubStr.o ../bin/utility/TSD.o ../bin/utility/EmptyTSD.o ../bin/utility/TailFinder.o ../bin/utility/Tail.o ../bin/utility/EmptyTail.o ../bin/tr/TrCollector.o ../bin/utility/GlobAlignE.o ../bin/utility/LocAlign.o ../bin/nonltr/ChromListMaker.o -lstdc++fs\n",
            "\n",
            "ðŸ” Checking for compiled binary...\n",
            "âœ… SUCCESS! Binary created at: /content/LtrDetector/bin/LtrDetector\n",
            "-rwxr-xr-x 1 root root 6034048 Jan 12 09:34 ../bin/LtrDetector\n",
            "| -arg     | Description | Default |\n",
            "| ---------------- | ----------- | ------- |\n",
            "| -fasta | Directory containing files to be scanned. Files must have .fa extension. | required |\n",
            "| -destDir | Output directory where the results are stored. | required |\n",
            "( IMPORTANT: Files under the output directory are deleted at the start of the program.)\n",
            "| -minLen | Minimum length of complete LTR-RTs. Constrains scoring system and filters. | 400 |\n",
            "| -maxLen |  Maximum length of complete LTR-RTs. Constrains scoring system and filters. | 22000 |\n",
            "| -minLenLTR | Minimum length of LTR direct repeat. Constrains filters. | 100 |\n",
            "| -maxLenLTR | Maximum length of LTR direct repeat. Constrains filters. | 6000 |\n",
            "( Note run time is highly dependent on this parameter, as it provides an upper bound for alignment length in the boundary adjustment step.)\n",
            "| -id | Minimum identity [0-100] between 5' and 3' LTRs. | 85 |\n",
            "| -k  | Length of k-mers to adjust scoring system. Tradeoff between noise and resistance to mutation. | 13 |\n",
            "| -plateauSeed | Minimum length of plateaus to be initially considered 'Keep' in merging step. | 10 |\n",
            "| -nThreads | Number of cores to be used. | 1 |\n",
            "| -gapTol | Number of base pairs that two plateaus can differ by in height/distance. Affects both plateau merging and pairing steps. | 200 |\n",
            "|-seqLevel| Forces parallel execution on sequences within multi-FASTA file. Loads all sequences into memory | disabled |\n",
            "| -rawScores | prints the raw scores to a file called xxxxRawScores.txt under the output directory. | disabled |\n",
            "| -cleanedScores | prints the scores after merging to a file called xxxxCleanedScores.txt under the output directory. | disabled |\n",
            "| -nested | searches for nested elements. Results are stored in seperate files (marked as xxxxNestedDetector.bed) under the output directory | disabled |\n",
            "| -bedFormat | prints BED format without additional annotations (PPT and TSD). | disabled |\n",
            "\n",
            "ðŸ“ Checking all bin directory contents:\n",
            "total 6944\n",
            "drwxr-xr-x 7 root root    4096 Jan 12 09:34 .\n",
            "drwxr-xr-x 5 root root    4096 Jan 12 09:33 ..\n",
            "drwxr-xr-x 2 root root    4096 Jan 12 09:34 exception\n",
            "-rwxr-xr-x 1 root root 6034048 Jan 12 09:34 LtrDetector\n",
            "drwxr-xr-x 2 root root    4096 Jan 12 09:34 nonltr\n",
            "drwxr-xr-x 2 root root    4096 Jan 12 09:33 test\n",
            "-rw-r--r-- 1 root root 1042912 Jan 12 09:34 TestTr.o\n",
            "drwxr-xr-x 2 root root    4096 Jan 12 09:34 tr\n",
            "drwxr-xr-x 2 root root    4096 Jan 12 09:34 utility\n",
            "\n",
            "âœ… Build process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 1: Fetch FASTA Sequence from NCBI**\n",
        "#@markdown Enter a valid NCBI accession number (e.g., NC_000913, CM001001).\n",
        "from Bio import Entrez, SeqIO\n",
        "import os\n",
        "\n",
        "# Prompt for accession number\n",
        "accession = input(\"ðŸ” Enter the NCBI accession number (e.g., NC_000913): \").strip()\n",
        "\n",
        "# It's good practice to provide your email for NCBI queries\n",
        "Entrez.email = \"your-email@example.com\"  # Consider changing this\n",
        "\n",
        "print(f\"ðŸ“¥ Downloading sequence for accession {accession}...\")\n",
        "try:\n",
        "    # Fetch the sequence\n",
        "    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
        "    record = SeqIO.read(handle, \"fasta\")\n",
        "    SeqIO.write(record, \"sequence.fasta\", \"fasta\")\n",
        "    handle.close()\n",
        "    print(f\"âœ… Downloaded: {record.id}, length: {len(record)} bp\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Download failed. Error: {e}\")\n",
        "    print(\"Please check your accession number and internet connection.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "06Vmtw6PAyZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b46544eb-7f51-4dbb-fdd4-6abc0895211e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Enter the NCBI accession number (e.g., NC_000913): NC_000913\n",
            "ðŸ“¥ Downloading sequence for accession NC_000913...\n",
            "âœ… Downloaded: NC_000913.3, length: 4641652 bp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 2: Clean the FASTA File**\n",
        "#@markdown This step removes very short sequences and those with too many unknown bases ('N's).\n",
        "def clean_fasta(input_file, output_file, min_length=500, max_n_percent=10.0):\n",
        "    \"\"\"Cleans a FASTA file based on length and N content.\"\"\"\n",
        "    from Bio import SeqIO\n",
        "    good_records = []\n",
        "    total_records = 0\n",
        "    removed = 0\n",
        "\n",
        "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
        "        total_records += 1\n",
        "        seq_len = len(record.seq)\n",
        "\n",
        "        # Calculate percentage of unknown bases ('N' or 'n')\n",
        "        n_count = str(record.seq).upper().count('N')\n",
        "        n_percent = (n_count / seq_len) * 100\n",
        "\n",
        "        # Apply filters\n",
        "        if seq_len >= min_length and n_percent <= max_n_percent:\n",
        "            good_records.append(record)\n",
        "        else:\n",
        "            removed += 1\n",
        "\n",
        "    # Save the cleaned records\n",
        "    SeqIO.write(good_records, output_file, \"fasta\")\n",
        "    print(f\"ðŸ§¹ Cleaning complete. Kept {len(good_records)} records, removed {removed}.\")\n",
        "    if len(good_records) == 0:\n",
        "        print(\"âš ï¸ Warning: No sequences passed the filters. Try adjusting min_length or max_n_percent.\")\n",
        "\n",
        "# Run the cleaning function\n",
        "clean_fasta(\"sequence.fasta\", \"cleaned_sequence.fasta\",\n",
        "            min_length=500, max_n_percent=10.0)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oA_n93ErBDiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b4afd5-6460-4270-de8f-9923da1c9321"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§¹ Cleaning complete. Kept 1 records, removed 0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 3: Run LtrDetector**\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "input_fasta = \"cleaned_sequence.fasta\"\n",
        "fasta_dir = \"ltr_input_dir\"      # Directory for FASTA files (required)\n",
        "output_dir = \"ltrdetector_output\"  # Output directory (required)\n",
        "binary_path = \"/content/LtrDetector/bin/LtrDetector\"\n",
        "\n",
        "print(f\"ðŸ”¬ Setting up LtrDetector run...\")\n",
        "\n",
        "# 1. Create the required directory structure\n",
        "print(f\"ðŸ“ Creating required directories...\")\n",
        "!rm -rf {fasta_dir} {output_dir} 2>/dev/null  # Clean previous runs\n",
        "!mkdir -p {fasta_dir}\n",
        "!mkdir -p {output_dir}\n",
        "\n",
        "# 2. Copy FASTA to the directory (LtrDetector expects .fa files in a directory)\n",
        "#    The help says \"Files must have .fa extension\"\n",
        "fa_file = f\"{fasta_dir}/genome.fa\"\n",
        "!cp {input_fasta} {fa_file}\n",
        "\n",
        "print(f\"âœ“ Input: {fa_file}\")\n",
        "print(f\"âœ“ Output directory: {output_dir}\")\n",
        "print(f\"âœ“ Binary: {binary_path}\")\n",
        "\n",
        "# 3. Run LtrDetector with correct parameters\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    print(f\"\\nðŸš€ Running LtrDetector with correct syntax...\")\n",
        "    result = subprocess.run([\n",
        "        binary_path,\n",
        "        \"-fasta\", fasta_dir,     # Directory containing .fa files\n",
        "        \"-destDir\", output_dir,  # Output directory\n",
        "        \"-minLen\", \"100\",        # Minimum LTR length (default: 400)\n",
        "        \"-maxLen\", \"5000\",       # Maximum LTR length\n",
        "        # Add other parameters as needed\n",
        "    ], capture_output=True, text=True, check=True)\n",
        "\n",
        "    print(\"âœ… LtrDetector finished successfully!\")\n",
        "\n",
        "    # Show any output from the program\n",
        "    if result.stdout:\n",
        "        print(f\"\\nðŸ“‹ Program output:\")\n",
        "        print(result.stdout[:1000])\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"âŒ Error (exit code: {e.returncode}):\")\n",
        "    if e.stderr:\n",
        "        print(f\"Stderr: {e.stderr[:500]}\")\n",
        "    if e.stdout:\n",
        "        print(f\"Stdout: {e.stdout[:500]}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nâ±ï¸  Runtime: {round(end_time - start_time, 2)} seconds\")\n",
        "\n",
        "# 4. Check and display results\n",
        "print(f\"\\nðŸ“Š Checking output in {output_dir}/...\")\n",
        "if os.path.exists(output_dir):\n",
        "    print(f\"ðŸ“ Contents of output directory:\")\n",
        "    !ls -la {output_dir}/\n",
        "\n",
        "    # Look for result files\n",
        "    result_files = !find {output_dir} -type f -name \"*.txt\" -o -name \"*.gff\" -o -name \"*.bed\" 2>/dev/null\n",
        "    if result_files:\n",
        "        print(f\"\\nðŸ” Found {len(result_files)} result file(s):\")\n",
        "        for file in result_files:\n",
        "            print(f\"\\nðŸ“„ {file}:\")\n",
        "            !head -10 {file} 2>/dev/null || echo \"  (Cannot display)\"\n",
        "    else:\n",
        "        print(f\"\\nðŸ” No standard result files found. Listing all files:\")\n",
        "        !find {output_dir} -type f 2>/dev/null\n",
        "else:\n",
        "    print(f\"âŒ Output directory not created!\")\n",
        "\n",
        "# 5. Convert results to GFF3 if needed\n",
        "print(f\"\\nðŸ”„ Preparing results for visualization...\")\n",
        "\n",
        "# Try to find and convert the main output file\n",
        "possible_outputs = [\n",
        "    f\"{output_dir}/predictions.txt\",\n",
        "    f\"{output_dir}/results.txt\",\n",
        "    f\"{output_dir}/ltr_predictions.txt\",\n",
        "    f\"{output_dir}/output.txt\"\n",
        "]\n",
        "\n",
        "gff3_file = \"ltr_predictions.gff3\"\n",
        "converted = False\n",
        "\n",
        "for out_file in possible_outputs:\n",
        "    if os.path.exists(out_file):\n",
        "        print(f\"âœ“ Found results: {out_file}\")\n",
        "        # Try to convert to GFF3\n",
        "        try:\n",
        "            with open(out_file, 'r') as f, open(gff3_file, 'w') as gff:\n",
        "                gff.write(\"##gff-version 3\\n\")\n",
        "                gff.write(f\"##source LtrDetector\\n\")\n",
        "                for i, line in enumerate(f):\n",
        "                    if line.strip() and not line.startswith(\"#\"):\n",
        "                        parts = line.strip().split()\n",
        "                        if len(parts) >= 3:\n",
        "                            # Simple conversion - adjust based on actual format\n",
        "                            seqid = parts[0] if len(parts) > 0 else \"sequence\"\n",
        "                            start = parts[1] if len(parts) > 1 else \"1\"\n",
        "                            end = parts[2] if len(parts) > 2 else \"100\"\n",
        "                            gff.write(f\"{seqid}\\tLtrDetector\\tLTR_retrotransposon\\t{start}\\t{end}\\t.\\t.\\t.\\t\")\n",
        "                            gff.write(f\"ID=ltr_{i+1};Tool=LtrDetector\\n\")\n",
        "            print(f\"âœ… Converted to GFF3: {gff3_file}\")\n",
        "            converted = True\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Could not convert {out_file}: {e}\")\n",
        "\n",
        "if not converted:\n",
        "    print(f\"âš ï¸  No results converted to GFF3. Creating placeholder...\")\n",
        "    with open(gff3_file, 'w') as f:\n",
        "        f.write(\"##gff-version 3\\n##placeholder - run LtrDetector manually\\n\")\n",
        "    print(f\"Created: {gff3_file}\")\n",
        "\n",
        "print(f\"\\nðŸ“ Final output files ready for visualization:\")\n",
        "!ls -la *.gff3 2>/dev/null"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m69r1QgMBN2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 4: Analyze & Visualize LTR Detection Results**\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Rectangle\n",
        "import textwrap\n",
        "import os\n",
        "\n",
        "print(\"ðŸ“Š ANALYZING LTR DETECTION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Parse the BED output file\n",
        "bed_file = \"ltrdetector_output/genomeDetector.bed\"\n",
        "print(f\"ðŸ“ˆ Parsing results from: {bed_file}\")\n",
        "\n",
        "try:\n",
        "    # Skip the first two header rows\n",
        "    df = pd.read_csv(bed_file, sep='\\t', skiprows=2, header=None)\n",
        "\n",
        "    # Assign column names based on the BED format\n",
        "    column_names = [\n",
        "        'Sequence', 'Retro_Start', 'Retro_End', 'LTR_Left_Start', 'LTR_Left_End',\n",
        "        'LTR_Right_Start', 'LTR_Right_End', 'Score', 'TSD_Left_Start', 'TSD_Left_End',\n",
        "        'TSD_Right_Start', 'TSD_Right_End', 'PPT_Start', 'PPT_End', 'Strand',\n",
        "        'Purine_Pct', 'TG_Start', 'TG_End'\n",
        "    ]\n",
        "\n",
        "    df.columns = column_names[:len(df.columns)]\n",
        "\n",
        "    print(f\"âœ… Successfully parsed {len(df)} LTR retrotransposons\")\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    df['Retro_Length'] = df['Retro_End'] - df['Retro_Start']\n",
        "    df['LTR_Left_Length'] = df['LTR_Left_End'] - df['LTR_Left_Start']\n",
        "    df['LTR_Right_Length'] = df['LTR_Right_End'] - df['LTR_Right_Start']\n",
        "    df['Internal_Region_Length'] = df['Retro_Length'] - (df['LTR_Left_Length'] + df['LTR_Right_Length'])\n",
        "    df['LTR_Similarity'] = df['Score']  # Score represents similarity between LTRs\n",
        "\n",
        "    # Display summary statistics\n",
        "    print(\"\\nðŸ“‹ SUMMARY STATISTICS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Total LTR Retrotransposons: {len(df)}\")\n",
        "    print(f\"Average Retrotransposon Length: {df['Retro_Length'].mean():.0f} bp\")\n",
        "    print(f\"Average LTR Length: {df['LTR_Left_Length'].mean():.0f} bp\")\n",
        "    print(f\"Average LTR Similarity: {df['LTR_Similarity'].mean():.1f}%\")\n",
        "    print(f\"Total bp occupied by LTRs: {df['Retro_Length'].sum():,} bp\")\n",
        "\n",
        "    # Check for TSD and PPT presence\n",
        "    has_TSD = ((df['TSD_Left_Start'] != '---') & (df['TSD_Right_Start'] != '---')).sum()\n",
        "    has_PPT = (df['PPT_Start'] != '---').sum()\n",
        "    print(f\"Elements with TSDs: {has_TSD}/{len(df)} ({has_TSD/len(df)*100:.1f}%)\")\n",
        "    print(f\"Elements with PPTs: {has_PPT}/{len(df)} ({has_PPT/len(df)*100:.1f}%)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error parsing BED file: {e}\")\n",
        "    print(\"Trying alternative parsing...\")\n",
        "    # Show raw data for debugging\n",
        "    with open(bed_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        print(f\"First 5 lines: {lines[:5]}\")\n",
        "\n",
        "# 2. Create Visualizations\n",
        "print(\"\\nðŸŽ¨ GENERATING VISUALIZATIONS...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Set up the figure grid\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "\n",
        "# Plot 1: Distribution of LTR Retrotransposon Lengths\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    plt.hist(df['Retro_Length'], bins=15, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    plt.xlabel('Retrotransposon Length (bp)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of LTR Retrotransposon Lengths')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    # Add mean line\n",
        "    mean_len = df['Retro_Length'].mean()\n",
        "    plt.axvline(mean_len, color='red', linestyle='--', linewidth=1,\n",
        "                label=f'Mean: {mean_len:.0f} bp')\n",
        "    plt.legend()\n",
        "\n",
        "# Plot 2: LTR Similarity Scores\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    similarity_scores = df['LTR_Similarity'].dropna()\n",
        "    plt.hist(similarity_scores, bins=10, edgecolor='black', alpha=0.7, color='coral')\n",
        "    plt.xlabel('LTR Similarity Score (%)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('LTR Pair Similarity Distribution')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    # Highlight high similarity elements\n",
        "    high_sim = (similarity_scores > 90).sum()\n",
        "    plt.text(0.05, 0.95, f'{high_sim} elements >90%',\n",
        "             transform=ax2.transAxes, fontsize=9, verticalalignment='top',\n",
        "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Plot 3: LTR Length Comparison\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    # Scatter plot of left vs right LTR lengths\n",
        "    plt.scatter(df['LTR_Left_Length'], df['LTR_Right_Length'],\n",
        "                alpha=0.6, color='green', s=50)\n",
        "\n",
        "    # Add perfect correlation line\n",
        "    max_len = max(df['LTR_Left_Length'].max(), df['LTR_Right_Length'].max())\n",
        "    plt.plot([0, max_len], [0, max_len], 'r--', alpha=0.5, label='Perfect match')\n",
        "\n",
        "    plt.xlabel('Left LTR Length (bp)')\n",
        "    plt.ylabel('Right LTR Length (bp)')\n",
        "    plt.title('LTR Length Symmetry')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "\n",
        "# Plot 4: Genomic Distribution (Position along chromosome)\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    positions = df['Retro_Start'].sort_values().values\n",
        "    y_pos = np.ones(len(positions))\n",
        "\n",
        "    plt.scatter(positions, y_pos, s=50, alpha=0.6, color='purple')\n",
        "    plt.yticks([])\n",
        "    plt.xlabel('Genomic Position (bp)')\n",
        "    plt.title('Genomic Distribution of LTR Retrotransposons')\n",
        "    plt.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    # Add density estimate\n",
        "    from scipy.stats import gaussian_kde\n",
        "    if len(positions) > 1:\n",
        "        kde = gaussian_kde(positions)\n",
        "        x_range = np.linspace(positions.min(), positions.max(), 100)\n",
        "        density = kde(x_range)\n",
        "        plt.plot(x_range, 0.5 + density/density.max()*0.5, 'b-', alpha=0.5, label='Density')\n",
        "        plt.legend()\n",
        "\n",
        "# Plot 5: Structure Diagram of Top Scoring Element\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    # Get the element with highest similarity score\n",
        "    best_idx = df['LTR_Similarity'].idxmax()\n",
        "    best = df.loc[best_idx]\n",
        "\n",
        "    # Create structure diagram\n",
        "    retro_start, retro_end = best['Retro_Start'], best['Retro_End']\n",
        "    ltr1_start, ltr1_end = best['LTR_Left_Start'], best['LTR_Left_End']\n",
        "    ltr2_start, ltr2_end = best['LTR_Right_Start'], best['LTR_Right_End']\n",
        "\n",
        "    # Draw the retrotransposon\n",
        "    plt.barh(0, retro_end - retro_start, left=retro_start, height=0.2,\n",
        "             color='lightgray', edgecolor='black', label='Internal Region')\n",
        "\n",
        "    # Draw LTRs\n",
        "    plt.barh(0, ltr1_end - ltr1_start, left=ltr1_start, height=0.3,\n",
        "             color='red', alpha=0.7, edgecolor='black', label='LTR')\n",
        "    plt.barh(0, ltr2_end - ltr2_start, left=ltr2_start, height=0.3,\n",
        "             color='red', alpha=0.7, edgecolor='black')\n",
        "\n",
        "    plt.yticks([])\n",
        "    plt.xlabel('Genomic Position (bp)')\n",
        "    plt.title(f'Structure of Best Element (Score: {best[\"LTR_Similarity\"]}%)')\n",
        "    plt.grid(True, alpha=0.3, axis='x')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Plot 6: Feature Presence Summary\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    features = {\n",
        "        'TSD': ((df['TSD_Left_Start'] != '---') & (df['TSD_Right_Start'] != '---')).sum(),\n",
        "        'PPT': (df['PPT_Start'] != '---').sum(),\n",
        "        'TG/CA': (df['TG_Start'] != '---').sum()\n",
        "    }\n",
        "\n",
        "    colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
        "    bars = plt.bar(range(len(features)), list(features.values()),\n",
        "                   color=colors, edgecolor='black')\n",
        "\n",
        "    plt.xticks(range(len(features)), list(features.keys()))\n",
        "    plt.ylabel('Number of Elements')\n",
        "    plt.title('Feature Presence in Detected LTRs')\n",
        "\n",
        "    # Add counts on top of bars\n",
        "    for bar, count in zip(bars, features.values()):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                 str(count), ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.suptitle('LTR Retrotransposon Analysis - Brassica rapa Chromosome A04',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "output_plot = \"ltr_analysis_summary.png\"\n",
        "plt.savefig(output_plot, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Saved summary plot: {output_plot}\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Create Detailed Report\n",
        "print(\"\\nðŸ“„ GENERATING DETAILED REPORT...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "report_file = \"ltr_analysis_report.txt\"\n",
        "with open(report_file, 'w') as f:\n",
        "    f.write(\"=\" * 60 + \"\\n\")\n",
        "    f.write(\"LTR RETROTRANSPOSON ANALYSIS REPORT\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"1. EXECUTION SUMMARY\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(f\"Input Genome: Brassica rapa cultivar Chiifu-401-42 chromosome A04\\n\")\n",
        "    f.write(f\"Tool Used: LtrDetector\\n\")\n",
        "    f.write(f\"Detection Parameters: minLen=100, maxLen=5000\\n\")\n",
        "    f.write(f\"Runtime: 51.01 seconds\\n\\n\")\n",
        "\n",
        "    f.write(\"2. DETECTION RESULTS\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    if 'df' in locals() and not df.empty:\n",
        "        f.write(f\"Total LTR Retrotransposons Detected: {len(df)}\\n\")\n",
        "        f.write(f\"Genomic Coverage: {df['Retro_Length'].sum():,} bp\\n\\n\")\n",
        "\n",
        "        f.write(\"3. STATISTICAL SUMMARY\\n\")\n",
        "        f.write(\"-\" * 40 + \"\\n\")\n",
        "        f.write(\"Retrotransposon Lengths:\\n\")\n",
        "        f.write(f\"  Mean: {df['Retro_Length'].mean():.0f} bp\\n\")\n",
        "        f.write(f\"  Min: {df['Retro_Length'].min():.0f} bp\\n\")\n",
        "        f.write(f\"  Max: {df['Retro_Length'].max():.0f} bp\\n\")\n",
        "        f.write(f\"  Std Dev: {df['Retro_Length'].std():.0f} bp\\n\\n\")\n",
        "\n",
        "        f.write(\"LTR Similarity Scores:\\n\")\n",
        "        f.write(f\"  Mean: {df['LTR_Similarity'].mean():.1f}%\\n\")\n",
        "        f.write(f\"  Range: {df['LTR_Similarity'].min():.0f}%-{df['LTR_Similarity'].max():.0f}%\\n\\n\")\n",
        "\n",
        "        f.write(\"4. INDIVIDUAL ELEMENT DETAILS\\n\")\n",
        "        f.write(\"-\" * 40 + \"\\n\")\n",
        "        for idx, row in df.iterrows():\n",
        "            f.write(f\"\\nElement #{idx+1}:\\n\")\n",
        "            f.write(f\"  Position: {row['Retro_Start']:,} - {row['Retro_End']:,} \"\n",
        "                   f\"({row['Retro_Length']:,} bp)\\n\")\n",
        "            f.write(f\"  LTR Left: {row['LTR_Left_Start']:,} - {row['LTR_Left_End']:,} \"\n",
        "                   f\"({row['LTR_Left_Length']:,} bp)\\n\")\n",
        "            f.write(f\"  LTR Right: {row['LTR_Right_Start']:,} - {row['LTR_Right_End']:,} \"\n",
        "                   f\"({row['LTR_Right_Length']:,} bp)\\n\")\n",
        "            f.write(f\"  Similarity Score: {row['LTR_Similarity']}%\\n\")\n",
        "            f.write(f\"  Strand: {'+' if row['Strand'] > 0 else '-' if row['Strand'] < 0 else 'Unknown'}\\n\")\n",
        "            f.write(f\"  Features: \")\n",
        "            features = []\n",
        "            if row['PPT_Start'] != '---':\n",
        "                features.append(\"PPT\")\n",
        "            if row['TG_Start'] != '---':\n",
        "                features.append(\"TG/CA\")\n",
        "            if row['TSD_Left_Start'] != '---':\n",
        "                features.append(\"TSD\")\n",
        "            f.write(', '.join(features) if features else \"None\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    f.write(f\"\\n\\n5. OUTPUT FILES\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(f\"Raw BED Output: {bed_file}\\n\")\n",
        "    f.write(f\"Summary Plot: {output_plot}\\n\")\n",
        "    f.write(f\"This Report: {report_file}\\n\")\n",
        "\n",
        "print(f\"âœ… Generated detailed report: {report_file}\")\n",
        "\n",
        "# 4. Export Data for Further Analysis\n",
        "print(\"\\nðŸ’¾ EXPORTING DATA FOR DOWNLOAD...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Create a clean CSV for further analysis\n",
        "if 'df' in locals() and not df.empty:\n",
        "    csv_file = \"ltr_retrotransposons_clean.csv\"\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"âœ… Exported clean data: {csv_file} ({len(df)} records)\")\n",
        "\n",
        "    # Create a simplified GFF3 file for genome browsers\n",
        "    gff3_file = \"ltr_predictions_clean.gff3\"\n",
        "    with open(gff3_file, 'w') as gff:\n",
        "        gff.write(\"##gff-version 3\\n\")\n",
        "        gff.write(\"##source LtrDetector v1.0\\n\")\n",
        "        gff.write(\"##genome Brassica rapa cultivar Chiifu-401-42 chromosome A04\\n\")\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            # Main retrotransposon feature\n",
        "            gff.write(f\"{row['Sequence'].split()[0]}\\tLtrDetector\\tLTR_retrotransposon\\t\")\n",
        "            gff.write(f\"{row['Retro_Start']}\\t{row['Retro_End']}\\t{row['LTR_Similarity']}\\t\")\n",
        "            gff.write(f\".\\t.\\tID=RT{idx+1};Name=LTR-RT_{idx+1};Score={row['LTR_Similarity']};\")\n",
        "            gff.write(f\"Length={row['Retro_Length']}\\n\")\n",
        "\n",
        "            # Left LTR\n",
        "            gff.write(f\"{row['Sequence'].split()[0]}\\tLtrDetector\\tLTR\\t\")\n",
        "            gff.write(f\"{row['LTR_Left_Start']}\\t{row['LTR_Left_End']}\\t.\\t\")\n",
        "            gff.write(f\".\\t.\\tID=RT{idx+1}_LTR1;Parent=RT{idx+1}\\n\")\n",
        "\n",
        "            # Right LTR\n",
        "            gff.write(f\"{row['Sequence'].split()[0]}\\tLtrDetector\\tLTR\\t\")\n",
        "            gff.write(f\"{row['LTR_Right_Start']}\\t{row['LTR_Right_End']}\\t.\\t\")\n",
        "            gff.write(f\".\\t.\\tID=RT{idx+1}_LTR2;Parent=RT{idx+1}\\n\")\n",
        "\n",
        "    print(f\"âœ… Created GFF3 for genome browsers: {gff3_file}\")\n",
        "\n",
        "# 5. Final Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ‰ ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nðŸ“Š KEY FINDINGS:\")\n",
        "print(f\"  â€¢ Found {len(df) if 'df' in locals() else 'N/A'} LTR retrotransposons\")\n",
        "print(f\"  â€¢ Total genomic coverage: {df['Retro_Length'].sum():,} bp\" if 'df' in locals() else \"\")\n",
        "print(f\"  â€¢ Average LTR similarity: {df['LTR_Similarity'].mean():.1f}%\" if 'df' in locals() else \"\")\n",
        "print(f\"  â€¢ Best conserved element: {df['LTR_Similarity'].max()}%\" if 'df' in locals() else \"\")\n",
        "\n",
        "print(\"\\nðŸ“ OUTPUT FILES GENERATED:\")\n",
        "output_files = [\n",
        "    (\"Summary Plot\", \"ltr_analysis_summary.png\"),\n",
        "    (\"Detailed Report\", \"ltr_analysis_report.txt\"),\n",
        "    (\"Clean CSV Data\", \"ltr_retrotransposons_clean.csv\"),\n",
        "    (\"GFF3 for Browsers\", \"ltr_predictions_clean.gff3\"),\n",
        "    (\"Raw BED Output\", \"ltrdetector_output/genomeDetector.bed\")\n",
        "]\n",
        "\n",
        "for desc, filepath in output_files:\n",
        "    if os.path.exists(filepath.split('/')[0] if '/' in filepath else filepath):\n",
        "        size = os.path.getsize(filepath)\n",
        "        print(f\"  â€¢ {desc:20} {filepath:30} ({size:,} bytes)\")\n",
        "\n",
        "print(\"\\nðŸ”¬ NEXT STEPS:\")\n",
        "print(\"  1. Load GFF3 file in genome browser (IGV, JBrowse)\")\n",
        "print(\"  2. Use CSV data for statistical analysis in R/Python\")\n",
        "print(\"  3. Compare with known LTR databases\")\n",
        "print(\"  4. Analyze evolutionary age using LTR divergence\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Bsu3uhl4826h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3dEKY5TCAGa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}