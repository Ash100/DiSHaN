{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNePQJYgcyZ6FkR7vy2LEDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/DiSHaN/blob/main/LTRDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This pipeline is generated by **Dr. Ashfaq Ahmad** for research purposes. It uses LTRDetector for genomes to identify and plot the presence of LTR Transposons.\n",
        "\n",
        "[Citation of LTRDector](https://link.springer.com/article/10.1186/s12864-019-5796-9)"
      ],
      "metadata": {
        "id": "iCeOOJyDJ3Gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 0: Initial Setup and Installation (~ 3 minutes)**\n",
        "#@markdown This cell installs dependencies, compiles Look4LTRs, and mounts Google Drive.\n",
        "print(\"ðŸš€ Starting pipeline setup...\")\n",
        "\n",
        "# 1. Install system dependencies including C++ build tools\n",
        "!apt-get update && apt-get install -y wget unzip cmake build-essential 2>/dev/null\n",
        "\n",
        "# 2. Install Python bioinformatics packages\n",
        "!pip install biopython pandas matplotlib numpy 2>/dev/null\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0ru4dKcEAmd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 0: Build LtrDetector (Following Official Instructions)**\n",
        "print(\"ðŸš€ Building LtrDetector using official method...\")\n",
        "\n",
        "# 1. Navigate to the src directory (as per README)\n",
        "import os\n",
        "os.chdir('/content/LtrDetector/src')\n",
        "\n",
        "print(\"ðŸ“ Current directory:\", os.getcwd())\n",
        "!ls -la\n",
        "\n",
        "# 2. Create the bin directory (first step in README)\n",
        "print(\"\\nðŸ“¦ Creating bin directory...\")\n",
        "!make bin 2>&1\n",
        "\n",
        "# 3. Build the actual binary (second step in README)\n",
        "print(\"\\nðŸ”¨ Compiling LtrDetector binary...\")\n",
        "!make tr -j4 2>&1\n",
        "\n",
        "# 4. Check if binary was created\n",
        "print(\"\\nðŸ” Checking for compiled binary...\")\n",
        "if os.path.exists('../bin/LtrDetector'):\n",
        "    print(f\"âœ… SUCCESS! Binary created at: /content/LtrDetector/bin/LtrDetector\")\n",
        "    !ls -la ../bin/LtrDetector\n",
        "    !../bin/LtrDetector -help 2>&1 | head -20\n",
        "else:\n",
        "    print(\"âŒ Binary not found. Checking for errors...\")\n",
        "    # Look for any binary files\n",
        "    !find .. -name \"*Ltr*\" -type f -executable 2>/dev/null\n",
        "    !find .. -name \"*ltr*\" -type f -executable 2>/dev/null\n",
        "\n",
        "print(\"\\nðŸ“ Checking all bin directory contents:\")\n",
        "!ls -la ../bin/ 2>/dev/null || echo \"bin directory not found\"\n",
        "\n",
        "# 5. Return to content directory\n",
        "os.chdir('/content')\n",
        "print(\"\\nâœ… Build process completed.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n4b_3RKGF71y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 1: Fetch FASTA Sequence from NCBI**\n",
        "#@markdown Enter a valid NCBI accession number (e.g., NC_000913, CM001001).\n",
        "from Bio import Entrez, SeqIO\n",
        "import os\n",
        "\n",
        "# Prompt for accession number\n",
        "accession = input(\"ðŸ” Enter the NCBI accession number (e.g., NC_000913): \").strip()\n",
        "\n",
        "# It's good practice to provide your email for NCBI queries\n",
        "Entrez.email = \"your-email@example.com\"  # Consider changing this\n",
        "\n",
        "print(f\"ðŸ“¥ Downloading sequence for accession {accession}...\")\n",
        "try:\n",
        "    # Fetch the sequence\n",
        "    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
        "    record = SeqIO.read(handle, \"fasta\")\n",
        "    SeqIO.write(record, \"sequence.fasta\", \"fasta\")\n",
        "    handle.close()\n",
        "    print(f\"âœ… Downloaded: {record.id}, length: {len(record)} bp\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Download failed. Error: {e}\")\n",
        "    print(\"Please check your accession number and internet connection.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "06Vmtw6PAyZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 2: Clean the FASTA File**\n",
        "#@markdown This step removes very short sequences and those with too many unknown bases ('N's).\n",
        "def clean_fasta(input_file, output_file, min_length=500, max_n_percent=10.0):\n",
        "    \"\"\"Cleans a FASTA file based on length and N content.\"\"\"\n",
        "    from Bio import SeqIO\n",
        "    good_records = []\n",
        "    total_records = 0\n",
        "    removed = 0\n",
        "\n",
        "    for record in SeqIO.parse(input_file, \"fasta\"):\n",
        "        total_records += 1\n",
        "        seq_len = len(record.seq)\n",
        "\n",
        "        # Calculate percentage of unknown bases ('N' or 'n')\n",
        "        n_count = str(record.seq).upper().count('N')\n",
        "        n_percent = (n_count / seq_len) * 100\n",
        "\n",
        "        # Apply filters\n",
        "        if seq_len >= min_length and n_percent <= max_n_percent:\n",
        "            good_records.append(record)\n",
        "        else:\n",
        "            removed += 1\n",
        "\n",
        "    # Save the cleaned records\n",
        "    SeqIO.write(good_records, output_file, \"fasta\")\n",
        "    print(f\"ðŸ§¹ Cleaning complete. Kept {len(good_records)} records, removed {removed}.\")\n",
        "    if len(good_records) == 0:\n",
        "        print(\"âš ï¸ Warning: No sequences passed the filters. Try adjusting min_length or max_n_percent.\")\n",
        "\n",
        "# Run the cleaning function\n",
        "clean_fasta(\"sequence.fasta\", \"cleaned_sequence.fasta\",\n",
        "            min_length=500, max_n_percent=10.0)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oA_n93ErBDiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 3: Run LtrDetector**\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "input_fasta = \"cleaned_sequence.fasta\"\n",
        "fasta_dir = \"ltr_input_dir\"      # Directory for FASTA files (required)\n",
        "output_dir = \"ltrdetector_output\"  # Output directory (required)\n",
        "binary_path = \"/content/LtrDetector/bin/LtrDetector\"\n",
        "\n",
        "print(f\"ðŸ”¬ Setting up LtrDetector run...\")\n",
        "\n",
        "# 1. Create the required directory structure\n",
        "print(f\"ðŸ“ Creating required directories...\")\n",
        "!rm -rf {fasta_dir} {output_dir} 2>/dev/null  # Clean previous runs\n",
        "!mkdir -p {fasta_dir}\n",
        "!mkdir -p {output_dir}\n",
        "\n",
        "# 2. Copy FASTA to the directory (LtrDetector expects .fa files in a directory)\n",
        "#    The help says \"Files must have .fa extension\"\n",
        "fa_file = f\"{fasta_dir}/genome.fa\"\n",
        "!cp {input_fasta} {fa_file}\n",
        "\n",
        "print(f\"âœ“ Input: {fa_file}\")\n",
        "print(f\"âœ“ Output directory: {output_dir}\")\n",
        "print(f\"âœ“ Binary: {binary_path}\")\n",
        "\n",
        "# 3. Run LtrDetector with correct parameters\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    print(f\"\\nðŸš€ Running LtrDetector with correct syntax...\")\n",
        "    result = subprocess.run([\n",
        "        binary_path,\n",
        "        \"-fasta\", fasta_dir,     # Directory containing .fa files\n",
        "        \"-destDir\", output_dir,  # Output directory\n",
        "        \"-minLen\", \"100\",        # Minimum LTR length (default: 400)\n",
        "        \"-maxLen\", \"5000\",       # Maximum LTR length\n",
        "        # Add other parameters as needed\n",
        "    ], capture_output=True, text=True, check=True)\n",
        "\n",
        "    print(\"âœ… LtrDetector finished successfully!\")\n",
        "\n",
        "    # Show any output from the program\n",
        "    if result.stdout:\n",
        "        print(f\"\\nðŸ“‹ Program output:\")\n",
        "        print(result.stdout[:1000])\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"âŒ Error (exit code: {e.returncode}):\")\n",
        "    if e.stderr:\n",
        "        print(f\"Stderr: {e.stderr[:500]}\")\n",
        "    if e.stdout:\n",
        "        print(f\"Stdout: {e.stdout[:500]}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nâ±ï¸  Runtime: {round(end_time - start_time, 2)} seconds\")\n",
        "\n",
        "# 4. Check and display results\n",
        "print(f\"\\nðŸ“Š Checking output in {output_dir}/...\")\n",
        "if os.path.exists(output_dir):\n",
        "    print(f\"ðŸ“ Contents of output directory:\")\n",
        "    !ls -la {output_dir}/\n",
        "\n",
        "    # Look for result files\n",
        "    result_files = !find {output_dir} -type f -name \"*.txt\" -o -name \"*.gff\" -o -name \"*.bed\" 2>/dev/null\n",
        "    if result_files:\n",
        "        print(f\"\\nðŸ” Found {len(result_files)} result file(s):\")\n",
        "        for file in result_files:\n",
        "            print(f\"\\nðŸ“„ {file}:\")\n",
        "            !head -10 {file} 2>/dev/null || echo \"  (Cannot display)\"\n",
        "    else:\n",
        "        print(f\"\\nðŸ” No standard result files found. Listing all files:\")\n",
        "        !find {output_dir} -type f 2>/dev/null\n",
        "else:\n",
        "    print(f\"âŒ Output directory not created!\")\n",
        "\n",
        "# 5. Convert results to GFF3 if needed\n",
        "print(f\"\\nðŸ”„ Preparing results for visualization...\")\n",
        "\n",
        "# Try to find and convert the main output file\n",
        "possible_outputs = [\n",
        "    f\"{output_dir}/predictions.txt\",\n",
        "    f\"{output_dir}/results.txt\",\n",
        "    f\"{output_dir}/ltr_predictions.txt\",\n",
        "    f\"{output_dir}/output.txt\"\n",
        "]\n",
        "\n",
        "gff3_file = \"ltr_predictions.gff3\"\n",
        "converted = False\n",
        "\n",
        "for out_file in possible_outputs:\n",
        "    if os.path.exists(out_file):\n",
        "        print(f\"âœ“ Found results: {out_file}\")\n",
        "        # Try to convert to GFF3\n",
        "        try:\n",
        "            with open(out_file, 'r') as f, open(gff3_file, 'w') as gff:\n",
        "                gff.write(\"##gff-version 3\\n\")\n",
        "                gff.write(f\"##source LtrDetector\\n\")\n",
        "                for i, line in enumerate(f):\n",
        "                    if line.strip() and not line.startswith(\"#\"):\n",
        "                        parts = line.strip().split()\n",
        "                        if len(parts) >= 3:\n",
        "                            # Simple conversion - adjust based on actual format\n",
        "                            seqid = parts[0] if len(parts) > 0 else \"sequence\"\n",
        "                            start = parts[1] if len(parts) > 1 else \"1\"\n",
        "                            end = parts[2] if len(parts) > 2 else \"100\"\n",
        "                            gff.write(f\"{seqid}\\tLtrDetector\\tLTR_retrotransposon\\t{start}\\t{end}\\t.\\t.\\t.\\t\")\n",
        "                            gff.write(f\"ID=ltr_{i+1};Tool=LtrDetector\\n\")\n",
        "            print(f\"âœ… Converted to GFF3: {gff3_file}\")\n",
        "            converted = True\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Could not convert {out_file}: {e}\")\n",
        "\n",
        "if not converted:\n",
        "    print(f\"âš ï¸  No results converted to GFF3. Creating placeholder...\")\n",
        "    with open(gff3_file, 'w') as f:\n",
        "        f.write(\"##gff-version 3\\n##placeholder - run LtrDetector manually\\n\")\n",
        "    print(f\"Created: {gff3_file}\")\n",
        "\n",
        "print(f\"\\nðŸ“ Final output files ready for visualization:\")\n",
        "!ls -la *.gff3 2>/dev/null"
      ],
      "metadata": {
        "cellView": "form",
        "id": "m69r1QgMBN2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Step 4: Analyze & Visualize LTR Detection Results**\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Rectangle\n",
        "import textwrap\n",
        "import os\n",
        "\n",
        "print(\"ðŸ“Š ANALYZING LTR DETECTION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Parse the BED output file\n",
        "bed_file = \"ltrdetector_output/genomeDetector.bed\"\n",
        "print(f\"ðŸ“ˆ Parsing results from: {bed_file}\")\n",
        "\n",
        "try:\n",
        "    # Skip the first two header rows\n",
        "    df = pd.read_csv(bed_file, sep='\\t', skiprows=2, header=None)\n",
        "\n",
        "    # Assign column names based on the BED format\n",
        "    column_names = [\n",
        "        'Sequence', 'Retro_Start', 'Retro_End', 'LTR_Left_Start', 'LTR_Left_End',\n",
        "        'LTR_Right_Start', 'LTR_Right_End', 'Score', 'TSD_Left_Start', 'TSD_Left_End',\n",
        "        'TSD_Right_Start', 'TSD_Right_End', 'PPT_Start', 'PPT_End', 'Strand',\n",
        "        'Purine_Pct', 'TG_Start', 'TG_End'\n",
        "    ]\n",
        "\n",
        "    df.columns = column_names[:len(df.columns)]\n",
        "\n",
        "    print(f\"âœ… Successfully parsed {len(df)} LTR retrotransposons\")\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    df['Retro_Length'] = df['Retro_End'] - df['Retro_Start']\n",
        "    df['LTR_Left_Length'] = df['LTR_Left_End'] - df['LTR_Left_Start']\n",
        "    df['LTR_Right_Length'] = df['LTR_Right_End'] - df['LTR_Right_Start']\n",
        "    df['Internal_Region_Length'] = df['Retro_Length'] - (df['LTR_Left_Length'] + df['LTR_Right_Length'])\n",
        "    df['LTR_Similarity'] = df['Score']  # Score represents similarity between LTRs\n",
        "\n",
        "    # Display summary statistics\n",
        "    print(\"\\nðŸ“‹ SUMMARY STATISTICS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Total LTR Retrotransposons: {len(df)}\")\n",
        "    print(f\"Average Retrotransposon Length: {df['Retro_Length'].mean():.0f} bp\")\n",
        "    print(f\"Average LTR Length: {df['LTR_Left_Length'].mean():.0f} bp\")\n",
        "    print(f\"Average LTR Similarity: {df['LTR_Similarity'].mean():.1f}%\")\n",
        "    print(f\"Total bp occupied by LTRs: {df['Retro_Length'].sum():,} bp\")\n",
        "\n",
        "    # Check for TSD and PPT presence\n",
        "    has_TSD = ((df['TSD_Left_Start'] != '---') & (df['TSD_Right_Start'] != '---')).sum()\n",
        "    has_PPT = (df['PPT_Start'] != '---').sum()\n",
        "    print(f\"Elements with TSDs: {has_TSD}/{len(df)} ({has_TSD/len(df)*100:.1f}%)\")\n",
        "    print(f\"Elements with PPTs: {has_PPT}/{len(df)} ({has_PPT/len(df)*100:.1f}%)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error parsing BED file: {e}\")\n",
        "    print(\"Trying alternative parsing...\")\n",
        "    # Show raw data for debugging\n",
        "    with open(bed_file, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        print(f\"First 5 lines: {lines[:5]}\")\n",
        "\n",
        "# 2. Create Visualizations\n",
        "print(\"\\nðŸŽ¨ GENERATING VISUALIZATIONS...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Set up the figure grid\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "\n",
        "# Plot 1: Distribution of LTR Retrotransposon Lengths\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    plt.hist(df['Retro_Length'], bins=15, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    plt.xlabel('Retrotransposon Length (bp)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of LTR Retrotransposon Lengths')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    # Add mean line\n",
        "    mean_len = df['Retro_Length'].mean()\n",
        "    plt.axvline(mean_len, color='red', linestyle='--', linewidth=1,\n",
        "                label=f'Mean: {mean_len:.0f} bp')\n",
        "    plt.legend()\n",
        "\n",
        "# Plot 2: LTR Similarity Scores\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    similarity_scores = df['LTR_Similarity'].dropna()\n",
        "    plt.hist(similarity_scores, bins=10, edgecolor='black', alpha=0.7, color='coral')\n",
        "    plt.xlabel('LTR Similarity Score (%)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('LTR Pair Similarity Distribution')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    # Highlight high similarity elements\n",
        "    high_sim = (similarity_scores > 90).sum()\n",
        "    plt.text(0.05, 0.95, f'{high_sim} elements >90%',\n",
        "             transform=ax2.transAxes, fontsize=9, verticalalignment='top',\n",
        "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Plot 3: LTR Length Comparison\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    # Scatter plot of left vs right LTR lengths\n",
        "    plt.scatter(df['LTR_Left_Length'], df['LTR_Right_Length'],\n",
        "                alpha=0.6, color='green', s=50)\n",
        "\n",
        "    # Add perfect correlation line\n",
        "    max_len = max(df['LTR_Left_Length'].max(), df['LTR_Right_Length'].max())\n",
        "    plt.plot([0, max_len], [0, max_len], 'r--', alpha=0.5, label='Perfect match')\n",
        "\n",
        "    plt.xlabel('Left LTR Length (bp)')\n",
        "    plt.ylabel('Right LTR Length (bp)')\n",
        "    plt.title('LTR Length Symmetry')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "\n",
        "# Plot 4: Genomic Distribution (Position along chromosome)\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    positions = df['Retro_Start'].sort_values().values\n",
        "    y_pos = np.ones(len(positions))\n",
        "\n",
        "    plt.scatter(positions, y_pos, s=50, alpha=0.6, color='purple')\n",
        "    plt.yticks([])\n",
        "    plt.xlabel('Genomic Position (bp)')\n",
        "    plt.title('Genomic Distribution of LTR Retrotransposons')\n",
        "    plt.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    # Add density estimate\n",
        "    from scipy.stats import gaussian_kde\n",
        "    if len(positions) > 1:\n",
        "        kde = gaussian_kde(positions)\n",
        "        x_range = np.linspace(positions.min(), positions.max(), 100)\n",
        "        density = kde(x_range)\n",
        "        plt.plot(x_range, 0.5 + density/density.max()*0.5, 'b-', alpha=0.5, label='Density')\n",
        "        plt.legend()\n",
        "\n",
        "# Plot 5: Structure Diagram of Top Scoring Element\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    # Get the element with highest similarity score\n",
        "    best_idx = df['LTR_Similarity'].idxmax()\n",
        "    best = df.loc[best_idx]\n",
        "\n",
        "    # Create structure diagram\n",
        "    retro_start, retro_end = best['Retro_Start'], best['Retro_End']\n",
        "    ltr1_start, ltr1_end = best['LTR_Left_Start'], best['LTR_Left_End']\n",
        "    ltr2_start, ltr2_end = best['LTR_Right_Start'], best['LTR_Right_End']\n",
        "\n",
        "    # Draw the retrotransposon\n",
        "    plt.barh(0, retro_end - retro_start, left=retro_start, height=0.2,\n",
        "             color='lightgray', edgecolor='black', label='Internal Region')\n",
        "\n",
        "    # Draw LTRs\n",
        "    plt.barh(0, ltr1_end - ltr1_start, left=ltr1_start, height=0.3,\n",
        "             color='red', alpha=0.7, edgecolor='black', label='LTR')\n",
        "    plt.barh(0, ltr2_end - ltr2_start, left=ltr2_start, height=0.3,\n",
        "             color='red', alpha=0.7, edgecolor='black')\n",
        "\n",
        "    plt.yticks([])\n",
        "    plt.xlabel('Genomic Position (bp)')\n",
        "    plt.title(f'Structure of Best Element (Score: {best[\"LTR_Similarity\"]}%)')\n",
        "    plt.grid(True, alpha=0.3, axis='x')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Plot 6: Feature Presence Summary\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "if 'df' in locals() and not df.empty:\n",
        "    features = {\n",
        "        'TSD': ((df['TSD_Left_Start'] != '---') & (df['TSD_Right_Start'] != '---')).sum(),\n",
        "        'PPT': (df['PPT_Start'] != '---').sum(),\n",
        "        'TG/CA': (df['TG_Start'] != '---').sum()\n",
        "    }\n",
        "\n",
        "    colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
        "    bars = plt.bar(range(len(features)), list(features.values()),\n",
        "                   color=colors, edgecolor='black')\n",
        "\n",
        "    plt.xticks(range(len(features)), list(features.keys()))\n",
        "    plt.ylabel('Number of Elements')\n",
        "    plt.title('Feature Presence in Detected LTRs')\n",
        "\n",
        "    # Add counts on top of bars\n",
        "    for bar, count in zip(bars, features.values()):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                 str(count), ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.suptitle('LTR Retrotransposon Analysis - Brassica rapa Chromosome A04',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "output_plot = \"ltr_analysis_summary.png\"\n",
        "plt.savefig(output_plot, dpi=300, bbox_inches='tight')\n",
        "print(f\"âœ… Saved summary plot: {output_plot}\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Create Detailed Report\n",
        "print(\"\\nðŸ“„ GENERATING DETAILED REPORT...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "report_file = \"ltr_analysis_report.txt\"\n",
        "with open(report_file, 'w') as f:\n",
        "    f.write(\"=\" * 60 + \"\\n\")\n",
        "    f.write(\"LTR RETROTRANSPOSON ANALYSIS REPORT\\n\")\n",
        "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"1. EXECUTION SUMMARY\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(f\"Input Genome: Brassica rapa cultivar Chiifu-401-42 chromosome A04\\n\")\n",
        "    f.write(f\"Tool Used: LtrDetector\\n\")\n",
        "    f.write(f\"Detection Parameters: minLen=100, maxLen=5000\\n\")\n",
        "    f.write(f\"Runtime: 51.01 seconds\\n\\n\")\n",
        "\n",
        "    f.write(\"2. DETECTION RESULTS\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    if 'df' in locals() and not df.empty:\n",
        "        f.write(f\"Total LTR Retrotransposons Detected: {len(df)}\\n\")\n",
        "        f.write(f\"Genomic Coverage: {df['Retro_Length'].sum():,} bp\\n\\n\")\n",
        "\n",
        "        f.write(\"3. STATISTICAL SUMMARY\\n\")\n",
        "        f.write(\"-\" * 40 + \"\\n\")\n",
        "        f.write(\"Retrotransposon Lengths:\\n\")\n",
        "        f.write(f\"  Mean: {df['Retro_Length'].mean():.0f} bp\\n\")\n",
        "        f.write(f\"  Min: {df['Retro_Length'].min():.0f} bp\\n\")\n",
        "        f.write(f\"  Max: {df['Retro_Length'].max():.0f} bp\\n\")\n",
        "        f.write(f\"  Std Dev: {df['Retro_Length'].std():.0f} bp\\n\\n\")\n",
        "\n",
        "        f.write(\"LTR Similarity Scores:\\n\")\n",
        "        f.write(f\"  Mean: {df['LTR_Similarity'].mean():.1f}%\\n\")\n",
        "        f.write(f\"  Range: {df['LTR_Similarity'].min():.0f}%-{df['LTR_Similarity'].max():.0f}%\\n\\n\")\n",
        "\n",
        "        f.write(\"4. INDIVIDUAL ELEMENT DETAILS\\n\")\n",
        "        f.write(\"-\" * 40 + \"\\n\")\n",
        "        for idx, row in df.iterrows():\n",
        "            f.write(f\"\\nElement #{idx+1}:\\n\")\n",
        "            f.write(f\"  Position: {row['Retro_Start']:,} - {row['Retro_End']:,} \"\n",
        "                   f\"({row['Retro_Length']:,} bp)\\n\")\n",
        "            f.write(f\"  LTR Left: {row['LTR_Left_Start']:,} - {row['LTR_Left_End']:,} \"\n",
        "                   f\"({row['LTR_Left_Length']:,} bp)\\n\")\n",
        "            f.write(f\"  LTR Right: {row['LTR_Right_Start']:,} - {row['LTR_Right_End']:,} \"\n",
        "                   f\"({row['LTR_Right_Length']:,} bp)\\n\")\n",
        "            f.write(f\"  Similarity Score: {row['LTR_Similarity']}%\\n\")\n",
        "            f.write(f\"  Strand: {'+' if row['Strand'] > 0 else '-' if row['Strand'] < 0 else 'Unknown'}\\n\")\n",
        "            f.write(f\"  Features: \")\n",
        "            features = []\n",
        "            if row['PPT_Start'] != '---':\n",
        "                features.append(\"PPT\")\n",
        "            if row['TG_Start'] != '---':\n",
        "                features.append(\"TG/CA\")\n",
        "            if row['TSD_Left_Start'] != '---':\n",
        "                features.append(\"TSD\")\n",
        "            f.write(', '.join(features) if features else \"None\")\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    f.write(f\"\\n\\n5. OUTPUT FILES\\n\")\n",
        "    f.write(\"-\" * 40 + \"\\n\")\n",
        "    f.write(f\"Raw BED Output: {bed_file}\\n\")\n",
        "    f.write(f\"Summary Plot: {output_plot}\\n\")\n",
        "    f.write(f\"This Report: {report_file}\\n\")\n",
        "\n",
        "print(f\"âœ… Generated detailed report: {report_file}\")\n",
        "\n",
        "# 4. Export Data for Further Analysis\n",
        "print(\"\\nðŸ’¾ EXPORTING DATA FOR DOWNLOAD...\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Create a clean CSV for further analysis\n",
        "if 'df' in locals() and not df.empty:\n",
        "    csv_file = \"ltr_retrotransposons_clean.csv\"\n",
        "    df.to_csv(csv_file, index=False)\n",
        "    print(f\"âœ… Exported clean data: {csv_file} ({len(df)} records)\")\n",
        "\n",
        "    # Create a simplified GFF3 file for genome browsers\n",
        "    gff3_file = \"ltr_predictions_clean.gff3\"\n",
        "    with open(gff3_file, 'w') as gff:\n",
        "        gff.write(\"##gff-version 3\\n\")\n",
        "        gff.write(\"##source LtrDetector v1.0\\n\")\n",
        "        gff.write(\"##genome Brassica rapa cultivar Chiifu-401-42 chromosome A04\\n\")\n",
        "\n",
        "        for idx, row in df.iterrows():\n",
        "            # Main retrotransposon feature\n",
        "            gff.write(f\"{row['Sequence'].split()[0]}\\tLtrDetector\\tLTR_retrotransposon\\t\")\n",
        "            gff.write(f\"{row['Retro_Start']}\\t{row['Retro_End']}\\t{row['LTR_Similarity']}\\t\")\n",
        "            gff.write(f\".\\t.\\tID=RT{idx+1};Name=LTR-RT_{idx+1};Score={row['LTR_Similarity']};\")\n",
        "            gff.write(f\"Length={row['Retro_Length']}\\n\")\n",
        "\n",
        "            # Left LTR\n",
        "            gff.write(f\"{row['Sequence'].split()[0]}\\tLtrDetector\\tLTR\\t\")\n",
        "            gff.write(f\"{row['LTR_Left_Start']}\\t{row['LTR_Left_End']}\\t.\\t\")\n",
        "            gff.write(f\".\\t.\\tID=RT{idx+1}_LTR1;Parent=RT{idx+1}\\n\")\n",
        "\n",
        "            # Right LTR\n",
        "            gff.write(f\"{row['Sequence'].split()[0]}\\tLtrDetector\\tLTR\\t\")\n",
        "            gff.write(f\"{row['LTR_Right_Start']}\\t{row['LTR_Right_End']}\\t.\\t\")\n",
        "            gff.write(f\".\\t.\\tID=RT{idx+1}_LTR2;Parent=RT{idx+1}\\n\")\n",
        "\n",
        "    print(f\"âœ… Created GFF3 for genome browsers: {gff3_file}\")\n",
        "\n",
        "# 5. Final Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ‰ ANALYSIS COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nðŸ“Š KEY FINDINGS:\")\n",
        "print(f\"  â€¢ Found {len(df) if 'df' in locals() else 'N/A'} LTR retrotransposons\")\n",
        "print(f\"  â€¢ Total genomic coverage: {df['Retro_Length'].sum():,} bp\" if 'df' in locals() else \"\")\n",
        "print(f\"  â€¢ Average LTR similarity: {df['LTR_Similarity'].mean():.1f}%\" if 'df' in locals() else \"\")\n",
        "print(f\"  â€¢ Best conserved element: {df['LTR_Similarity'].max()}%\" if 'df' in locals() else \"\")\n",
        "\n",
        "print(\"\\nðŸ“ OUTPUT FILES GENERATED:\")\n",
        "output_files = [\n",
        "    (\"Summary Plot\", \"ltr_analysis_summary.png\"),\n",
        "    (\"Detailed Report\", \"ltr_analysis_report.txt\"),\n",
        "    (\"Clean CSV Data\", \"ltr_retrotransposons_clean.csv\"),\n",
        "    (\"GFF3 for Browsers\", \"ltr_predictions_clean.gff3\"),\n",
        "    (\"Raw BED Output\", \"ltrdetector_output/genomeDetector.bed\")\n",
        "]\n",
        "\n",
        "for desc, filepath in output_files:\n",
        "    if os.path.exists(filepath.split('/')[0] if '/' in filepath else filepath):\n",
        "        size = os.path.getsize(filepath)\n",
        "        print(f\"  â€¢ {desc:20} {filepath:30} ({size:,} bytes)\")\n",
        "\n",
        "print(\"\\nðŸ”¬ NEXT STEPS:\")\n",
        "print(\"  1. Load GFF3 file in genome browser (IGV, JBrowse)\")\n",
        "print(\"  2. Use CSV data for statistical analysis in R/Python\")\n",
        "print(\"  3. Compare with known LTR databases\")\n",
        "print(\"  4. Analyze evolutionary age using LTR divergence\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Bsu3uhl4826h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3dEKY5TCAGa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}